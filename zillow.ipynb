{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "statutory-madagascar",
   "metadata": {},
   "source": [
    "# Title goes here\n",
    "## Introduction goes here\n",
    "Intro body goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accepting-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import usaddress\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from seleniumwire import webdriver\n",
    "# from seleniumwire.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "another-password",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "growing-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_num_result(input_string):\n",
    "    try:\n",
    "        # remove ',' in numerical result\n",
    "        input_string = input_string.replace(',', '')\n",
    "        regex_num_result = re.compile('(\\d+)')\n",
    "        # should be a list of all numerical values in the input_string\n",
    "        num_result_list = regex_num_result.search(input_string)\n",
    "        return int(num_result_list.group())\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "def parse_summary(input_string):\n",
    "    num_bed = None\n",
    "    num_bath = None\n",
    "    area = None\n",
    "    \n",
    "    input_string = input_string.replace(',', '')\n",
    "    regex_summary = re.compile('([\\d\\.]*).*bd([\\d\\.]*).*ba([\\d\\.]*).*sqft')\n",
    "    summary_list = regex_summary.search(input_string)\n",
    "    if summary_list.group(1) != '':\n",
    "        num_bed = int(summary_list.group(1))\n",
    "    if summary_list.group(2) != '':\n",
    "        num_bath = float(summary_list.group(2))\n",
    "    if summary_list.group(3) != '':\n",
    "        area = int(summary_list.group(3))\n",
    "    return num_bed, num_bath, area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-johnston",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# url\n",
    "# https://www.zillow.com/pittsburgh-pa/rentals/\n",
    "# https://www.zillow.com/pittsburgh-pa/rentals/2_p/\n",
    "# 40 results per page\n",
    "\n",
    "def get_url(page_num):\n",
    "    base = 'https://www.zillow.com/pittsburgh-pa/rentals/'\n",
    "    if page_num == 1:\n",
    "        return base\n",
    "    else:\n",
    "        return base + str(page_num) + '_p/'\n",
    "\n",
    "def parse_scores(address):\n",
    "    url = 'https://www.walkscore.com/score/' + address\n",
    "    response = requests.get(url)\n",
    "    root = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    regex_score = re.compile('(\\d+).svg')\n",
    "    \n",
    "    walk_score = None\n",
    "    tran_score = None\n",
    "    \n",
    "    walk_score_content = root.find('div', {'class': 'block-header-badge score-info-link', 'data-eventsrc': 'score page walk badge'})\n",
    "    tran_score_content = root.find('div', {'class': 'block-header-badge score-info-link', 'data-eventsrc': 'score page transit badge'})\n",
    "    if walk_score_content != None:\n",
    "        walk_score = int(regex_score.search(str(walk_score_content)).group(1))\n",
    "    if tran_score_content != None:\n",
    "        tran_score = int(regex_score.search(str(tran_score_content)).group(1))\n",
    "    return walk_score, tran_score\n",
    "        \n",
    "def parse_zillow_search_page(url):\n",
    "    headers = {\n",
    "       'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "       'accept-encoding': 'gzip, deflate, br',\n",
    "       'accept-language': 'en-US,en;q=0.8',\n",
    "       'upgrade-insecure-requests': '1',\n",
    "       'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    root = BeautifulSoup(response.content, 'html.parser')\n",
    "#     print(root)\n",
    "#     num_result = parse_num_result(root.find('span', {'class':'result-count'}).get_text())\n",
    "    \n",
    "    df = pd.DataFrame(columns=['Price', 'Address', 'PropertyType', 'Beds', 'Baths', 'Sqft', 'YearBuilt', 'WalkScore', 'TransitScore',\n",
    "                               'ParkingPrice', 'ParkingType', 'Cooling', 'Laundry', 'Description'])\n",
    "    \n",
    "    df = df.astype({'Price': 'float64', 'PropertyType': 'int64', 'Beds': 'int64', 'Baths': 'float64', 'Sqft': 'float64',\n",
    "                   'YearBuilt': 'int64', 'WalkScore': 'int64', 'TransitScore': 'int64', 'ParkingPrice': 'int64', 'ParkingType': 'int64', 'Cooling': 'bool',\n",
    "                   'Laundry': 'int64'})\n",
    "    \n",
    "    for div in root.find_all('div', {'class': 'list-card-info'}):\n",
    "        for a in div.find_all('a', {'class': 'list-card-link list-card-link-top-margin'}):\n",
    "            sub_url = a['href']\n",
    "            time.sleep(0.1)\n",
    "            results = None\n",
    "            # apartment with special listing\n",
    "            if sub_url.startswith('/b/'):\n",
    "                sub_url = 'https://www.zillow.com' + sub_url\n",
    "                results = parse_zillow_apartment_page(sub_url)\n",
    "            # house\n",
    "            else:\n",
    "                results = parse_zillow_house_page(sub_url)\n",
    "            if results != None:\n",
    "                for result in results:\n",
    "                    df = df.append(pd.Series(result, index=df.columns), ignore_index=True)\n",
    "#     print(df)\n",
    "    return df\n",
    "    \n",
    "                \n",
    "                \n",
    "# https://www.zillow.com/b/401-s-aiken-ave-pittsburgh-pa-9PRKLw/\n",
    "def parse_zillow_apartment_page(url):\n",
    "    if url == None or url == '':\n",
    "        return None\n",
    "    print(url)\n",
    "    headers = {\n",
    "       'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "       'accept-encoding': 'gzip, deflate, br',\n",
    "       'accept-language': 'en-US,en;q=0.8',\n",
    "       'upgrade-insecure-requests': '1',\n",
    "       'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    root = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    low_prices = []\n",
    "    high_prices = []\n",
    "    areas = []\n",
    "    num_beds = []\n",
    "    num_baths = []\n",
    "    \n",
    "    units = root.find('div', {'id': 'building-floorplan-card-group'})\n",
    "    if units == None:\n",
    "        units = root.find('div', {'data-test-id': 'BuildingUnitsCardGroup'})\n",
    "    if units == None:\n",
    "        return None\n",
    "    for div in units.children:\n",
    "#         if not div.has_attr('style'):\n",
    "        price_text = div.find('div', {'class': 'units-table__text--sectionheading'})\n",
    "        if price_text == None:\n",
    "            price_text = div.find('span', {'class': 'unit-card__unit-price units-table__text--sectionheading'})\n",
    "        price_text = price_text.get_text()\n",
    "        if '-' in price_text:\n",
    "            low_price = parse_num_result(price_text.split('-')[0])\n",
    "            high_price = parse_num_result(price_text.split('-')[1])\n",
    "        else:\n",
    "            price = parse_num_result(price_text)\n",
    "            low_price = price\n",
    "            high_price = price\n",
    "        low_prices.append(low_price)\n",
    "        high_prices.append(high_price)\n",
    "\n",
    "        for index, span in enumerate(div.find_all('span', {'class': 'units-table__text--smallbody bdp-home-dna-val'})):\n",
    "            if index == 0 and span.get_text() == 'Studio': \n",
    "                num_beds.append(0)\n",
    "            elif index == 0:\n",
    "                if span.get_text() == '--':\n",
    "                    num_beds.append(None)\n",
    "                else:\n",
    "                    num_beds.append(int(span.get_text()))\n",
    "            elif index == 1: \n",
    "                if span.get_text() == '--':\n",
    "                    num_baths.append(None)\n",
    "                else:\n",
    "                    num_baths.append(float(span.get_text()))\n",
    "            elif index == 2: \n",
    "                if span.get_text() == '--':\n",
    "                    areas.append(None)\n",
    "                else:\n",
    "                    areas.append(float(parse_num_result(span.get_text())))\n",
    "    cooling = None\n",
    "    parking_type = None\n",
    "    laundry = None\n",
    "    parking_price = None\n",
    "    walk_score = None\n",
    "    tran_score = None\n",
    "    address_st = None\n",
    "    year_built = None\n",
    "    description = None\n",
    "    property_type = 0\n",
    "    \n",
    "    try:\n",
    "        description = root.find('div', {'data-test-id': 'bdp-description'}).get_text()\n",
    "    except AttributeError:\n",
    "        description = None\n",
    "    \n",
    "    address = root.find('h2', {'data-test-id': 'bdp-building-address'})\n",
    "    if address == None:\n",
    "        return None\n",
    "    address = address.get_text()\n",
    "    if 'Undisclosed' in address:\n",
    "        return None\n",
    "    regex_address_st = re.compile('(.+)(Ave|Rd|Blvd|St|Dr|Sq|Way|Ct|Pl|Ln|Ctr|Cir|Ter)\\s?(N|S|E|W)?(?:.*?)(,[\\w\\s]+)(,.+)')\n",
    "    address = regex_address_st.search(address)\n",
    "    if address == None:\n",
    "        address = root.find('h2', {'data-test-id': 'bdp-building-address'}).get_text()\n",
    "        address = address.replace('#xA0', ' ')\n",
    "        address = regex_address_st.search(address)\n",
    "    if address == None:\n",
    "        return None   \n",
    "    address_st = str(''.join([x for x in address.groups() if x != None]))\n",
    "    walk_score, tran_score = parse_scores(address_st)\n",
    "    \n",
    "    # check facts top summary\n",
    "    facts_top = root.find('div', {'id': 'bdp-building-amenities-summary'})\n",
    "    if facts_top != None:\n",
    "        for div in facts_top.find_all('div', {'class': 'Flex-c11n-8-29-0__n94bjd-0 iQllGd'}):\n",
    "            if 'Year Built' in div.get_text():\n",
    "                year_built = parse_num_result(div.get_text())\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    for li in root.find_all('li', {'class': 'Flex-c11n-8-29-0__n94bjd-0 eegotE'}):\n",
    "        info_text = li.get_text().lower()\n",
    "        if 'cooling' in info_text:\n",
    "            cooling = True\n",
    "        elif 'parking' in info_text:\n",
    "            parking_type  = 1\n",
    "            if 'covered parking' in info_text:\n",
    "                parking_price = 0\n",
    "\n",
    "    # check building amenities\n",
    "    building_amenities = root.find('div', {'data-test-id': 'Building amenities', 'class': 'sc-irlOZD fAFzrt'})\n",
    "    if building_amenities != None:\n",
    "        building_amenities_text = building_amenities.get_text().lower()\n",
    "        if 'parking' in building_amenities_text or 'garage' in building_amenities_text:\n",
    "            parking_type = 1\n",
    "        if 'laundry' in building_amenities_text or 'washer' in building_amenities_text or 'dryer' in building_amenities_text:\n",
    "            laundry = 1\n",
    "            \n",
    "    # check unit amenities\n",
    "    unit_amenities = root.find('div', {'data-test-id': 'Unit features', 'class': 'sc-irlOZD fAFzrt'})\n",
    "    if unit_amenities != None:\n",
    "        unit_amenities_text = unit_amenities.get_text().lower()\n",
    "        if 'washer' in unit_amenities_text or 'dryer' in unit_amenities_text:\n",
    "            laundry = 2\n",
    "                \n",
    "    policies = root.find('div', {'data-test-id': 'building-policies'})\n",
    "    if policies != None and parking_price == None:\n",
    "        parking_policies = policies.find('div', {'data-test-id': 'building-policy-parking'})\n",
    "        if parking_policies != None:\n",
    "            parking_policies_text = parking_policies.get_text()    \n",
    "            regex_parking_price = re.compile('\\$(\\d+)')\n",
    "            parking_price_lists = regex_parking_price.search(parking_policies_text)\n",
    "            if parking_price_lists != None:\n",
    "                parking_price = min([parse_num_result(x) for x in parking_price_lists.groups()])\n",
    "    \n",
    "    common_result = [year_built, walk_score, tran_score, \n",
    "              parking_price, parking_type, cooling, laundry, description]\n",
    "    result = []\n",
    "    for i in range(len(low_prices)):\n",
    "        result.append([low_prices[i], address_st, property_type, num_beds[i], num_baths[i], areas[i]] + common_result)\n",
    "    return result\n",
    "    \n",
    "    \n",
    "            \n",
    "# https://www.zillow.com/homedetails/151-Robinson-St-38-Pittsburgh-PA-15213/2071373848_zpid/\n",
    "def parse_zillow_house_page(url):\n",
    "    if url == None or url == '':\n",
    "        return None\n",
    "    print(url)\n",
    "    headers = {\n",
    "       'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "       'accept-encoding': 'gzip, deflate, br',\n",
    "       'accept-language': 'en-US,en;q=0.8',\n",
    "       'upgrade-insecure-requests': '1',\n",
    "       'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    root = BeautifulSoup(response.content, 'html.parser')\n",
    "    try:\n",
    "        price = parse_num_result(root.find('span', {'class': 'Text-c11n-8-33-0__aiai24-0 sc-pkUbs dbPIZT'}).get_text())\n",
    "        low_price = price\n",
    "        high_price = price\n",
    "    except AttributeError:\n",
    "        price = None\n",
    "    \n",
    "    try:\n",
    "        address = root.find('title').get_text()\n",
    "        if 'Undisclosed' in address:\n",
    "            return None\n",
    "        address = address.replace('| Zillow', '')\n",
    "        regex_address_st = re.compile('(.+)(Ave|Rd|Blvd|St|Dr|Sq|Way|Ct|Pl|Ln|Ctr|Cir|Ter)\\s?(N|S|E|W)?(?:.*?)(,[\\w\\s]+)(,.+)')\n",
    "        address = regex_address_st.search(address)\n",
    "        if address == None:\n",
    "            address = root.find('h2', {'class': 'Text-c11n-8-33-0__aiai24-0 eAgJuz ds-price-change-address-row'}).get_text()\n",
    "            address = address.replace('#xA0', ' ')\n",
    "            address = regex_address_st.search(address)\n",
    "        if address == None:\n",
    "            return None\n",
    "        address_st = str(''.join([x for x in address.groups() if x != None]))\n",
    "    except AttributeError:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        property_icon = root.find('i', {'class': 'sc-qPLKk fonsds zsg-icon-buildings'})\n",
    "        property_type = property_icon.find_next_sibling('span', {'class': 'Text-c11n-8-33-0__aiai24-0 sc-pAyMl eWnzUA'}).get_text()\n",
    "        property_type = 0 if property_type == 'Apartment' or property_type == 'Studio' else 1 if property_type == 'SingleFamily' or property_type == 'Townhouse' else 2\n",
    "    except AttributeError:\n",
    "        property_type = None\n",
    "        \n",
    "    try:\n",
    "        summary_row = root.find('div', {'class': 'ds-summary-row'}).find('div', {'class': 'ds-bed-bath-living-area-header'}).get_text()\n",
    "        num_bed, num_bath, area = parse_summary(summary_row)\n",
    "    except AttributeError:\n",
    "        num_bed = None\n",
    "        num_bath = None\n",
    "        area = None\n",
    "        \n",
    "    try:\n",
    "        year_built = None\n",
    "        condition = root.find('h6', {'class': 'Text-c11n-8-33-0__aiai24-0 flSprY'}, text='Condition')\n",
    "        condition_detail = condition.find_next_sibling()\n",
    "        for span in condition_detail.find_all('span', {'class': 'Text-c11n-8-33-0__aiai24-0 kTUCqv'}):\n",
    "            if 'Year built' in span.get_text():\n",
    "                year_built = parse_num_result(span.get_text())\n",
    "    except AttributeError:\n",
    "        year_built = None\n",
    "        \n",
    "    try:\n",
    "        parking_price = None\n",
    "        parking_type = None\n",
    "        parking_icon = root.find('i', {'class': 'sc-qPLKk fonsds zsg-icon-parking'})\n",
    "        parking_type = parking_icon.find_next_sibling('span', {'class': 'Text-c11n-8-33-0__aiai24-0 sc-pAyMl eWnzUA'}).get_text() \n",
    "        parking_price = 0 if 'Garage' in parking_type and property_type == 1 else 0 if 'Off' in parking_type else None\n",
    "        parking_type = 0 if 'None' in parking_type else 1  \n",
    "    except AttributeError:\n",
    "        parking_type = None\n",
    "        parking_price = None\n",
    "    \n",
    "    try:\n",
    "        cooling = None\n",
    "        cooling_icon = root.find('i', {'class': 'sc-qPLKk fonsds zsg-icon-snowflake'})\n",
    "        if cooling_icon != None:\n",
    "            cooling_type = cooling_icon.find_next_sibling('span', {'class': 'Text-c11n-8-33-0__aiai24-0 sc-pAyMl eWnzUA'}).get_text()\n",
    "            if cooling_type != None and cooling_type != 'None':\n",
    "                cooling = True\n",
    "            elif cooling_type == 'None':\n",
    "                cooling = False\n",
    "    except AttributeError:\n",
    "        cooling = None\n",
    "        \n",
    "    try:\n",
    "        laundry = None\n",
    "        laundry_icon = root.find('i', {'class': 'sc-qPLKk fonsds zsg-icon-laundry'})\n",
    "        laundry_type = laundry_icon.find_next_sibling('span', {'class': 'Text-c11n-8-33-0__aiai24-0 sc-pAyMl eWnzUA'}).get_text()\n",
    "        laundry = 1 if laundry_type == 'In Unit' else 0\n",
    "    except AttributeError:\n",
    "        laundry = None   \n",
    "           \n",
    "    try:\n",
    "        description = root.find('div', {'class': 'ds-overview-section'}).get_text()\n",
    "    except AttributeError:\n",
    "        description = None    \n",
    "\n",
    "    walk_score = None\n",
    "    tran_score = None\n",
    "    walk_score, tran_score = parse_scores(address_st)\n",
    "    \n",
    "    result = [[low_price, address_st, property_type, num_bed, num_bath, area, year_built, walk_score, tran_score, \n",
    "              parking_price, parking_type, cooling, laundry, description]]\n",
    "    return result;\n",
    "    \n",
    "\n",
    "\n",
    "df = parse_zillow_search_page(get_url(1))\n",
    "for i in range(2, 21):\n",
    "    print(i)\n",
    "    df = df.append(parse_zillow_search_page(get_url(i)))\n",
    "df.to_csv('zillow_test.csv', encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# parse_zillow_house_page('https://www.zillow.com/homedetails/5541-Beeler-St-Pittsburgh-PA-15217/11629387_zpid/')\n",
    "# print(parse_zillow_apartment_page('https://www.zillow.com/b/914-western-avenue-wt-914-4-pittsburgh-pa-5fwkYK/'))\n",
    "# parse_scores('10428 Lindberg Ave, Pittsburgh, PA 15235')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fresh-blake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('AddressNumber', '902'),\n",
       "             ('StreetName', 'PJ McArdle'),\n",
       "             ('StreetNamePostType', 'Rd'),\n",
       "             ('PlaceName', 'Pittsburgh'),\n",
       "             ('StateName', 'PA'),\n",
       "             ('ZipCode', '15203')])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addr = '''902 PJ McArdle Rd, Pittsburgh, PA 15203'''\n",
    "\n",
    "addr = addr.replace('\\n', ' ')\n",
    "addr = addr.replace('CtE', 'Ct')\n",
    "# addr = addr.replace('CtE', 'Ct')\n",
    "usaddress.tag(addr)[0]\n",
    "# normalize_address_record(addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "demanding-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool_object_to_float(input_value):\n",
    "    if input_value == '':\n",
    "        return 0.0\n",
    "    elif input_value is True:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def numerical_object_to_float(input_value):\n",
    "    if isinstance(input_value, float) and np.isnan(input_value):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(input_value)\n",
    "    \n",
    "def median_without_nan(df):\n",
    "    return df.median(skipna=True, axis=0, numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "likely-easter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = np.nan\n",
    "print(np.nan == None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "everyday-preparation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PropertyType       0.0\n",
      "Beds               2.0\n",
      "Baths              1.0\n",
      "Sqft             886.0\n",
      "YearBuilt       1950.0\n",
      "WalkScore         83.0\n",
      "TransitScore      64.0\n",
      "ParkingPrice       0.0\n",
      "ParkingType        1.0\n",
      "Cooling            1.0\n",
      "Laundry            1.0\n",
      "Price           1266.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def load_file():\n",
    "    zillow_file = 'zillow.csv'\n",
    "    ap_file = 'apartments.csv'\n",
    "    apf_file = 'apartmentfinder.csv'\n",
    "    \n",
    "    df_zillow = pd.read_csv(zillow_file, header=0, sep=',', quotechar='\"', dtype=object, keep_default_na=True)\n",
    "    df_ap = pd.read_csv(ap_file, header=0, sep=',', quotechar='\"', dtype=object, keep_default_na=True)\n",
    "    df_apf = pd.read_csv(apf_file, header=0, sep=',', quotechar='\"', dtype=object, keep_default_na=True)\n",
    "    \n",
    "    df_ap.drop_duplicates(subset=['Address', 'Price', 'Beds', 'Baths', 'Sqft'], inplace=True, ignore_index=True)\n",
    "    \n",
    "    df_ap['Description'] = df_ap['Description'] + df_ap['Amenities']\n",
    "    df_ap.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Amenities'], inplace=True)\n",
    "    \n",
    "    return df_zillow, df_ap, df_apf\n",
    "\n",
    "def format_address(df):\n",
    "\n",
    "    # some patches in address name in order to use usaddress parser\n",
    "    df['AddressFormatted'] = df['Address'].apply(lambda x: x.replace('\\n', ' '))\n",
    "    df['AddressFormatted'] = df['AddressFormatted'].apply(lambda x: x.replace('CtE', 'Ct'))\n",
    "    df['AddressFormatted'] = df['AddressFormatted'].apply(lambda x: x.replace('249 Ave', '249 A Ave'))\n",
    "    df['AddressFormatted'] = df['AddressFormatted'].apply(lambda x: x.replace('Roadway', 'Rd'))\n",
    "    df['AddressFormatted'] = df['AddressFormatted'].apply(lambda x: x.split('â€“', 1)[0])\n",
    "    # parse\n",
    "    df['AddressFormatted'] = df['AddressFormatted'].apply(lambda x: usaddress.tag(x)[0]['AddressNumber'] + ' ' + usaddress.tag(x)[0]['StreetName'] + ' ' + \n",
    "                                                          usaddress.tag(x)[0]['StreetNamePostType'] + ' ' + usaddress.tag(x)[0]['PlaceName'] + ' ' + \n",
    "                                                          usaddress.tag(x)[0]['StateName'] + ' ' + usaddress.tag(x)[0]['ZipCode'])\n",
    "    return df\n",
    "\n",
    "def count_na(df):\n",
    "    df['NACount'] = df.isna().sum(axis=1)\n",
    "    return df\n",
    "\n",
    "def merge_df(df_zillow, df_ap, df_apf):\n",
    "    df_zillow = format_address(df_zillow)\n",
    "    df_ap = format_address(df_ap)\n",
    "    df_apf = format_address(df_apf)\n",
    "    \n",
    "    df_zillow = count_na(df_zillow)\n",
    "    df_ap = count_na(df_ap)\n",
    "    df_apf = count_na(df_apf)\n",
    "    \n",
    "    df = df_zillow.copy()\n",
    "    \n",
    "    while not df_apf.empty:\n",
    "        new_address = df_apf.iloc[0]['AddressFormatted']\n",
    "        if new_address in df['AddressFormatted'].values:\n",
    "            old_na_count = df[df['AddressFormatted'] == new_address].iloc[0]['NACount']\n",
    "            new_na_count = df_apf.iloc[0]['NACount']\n",
    "            if new_na_count < old_na_count:\n",
    "                df = df[~(df['AddressFormatted'] == new_address)]\n",
    "                df = df.append(df_apf[df_apf['AddressFormatted'] == new_address])\n",
    "        df_apf = df_apf[df_apf['AddressFormatted'] != new_address]\n",
    "        \n",
    "    while not df_ap.empty:\n",
    "        new_address = df_ap.iloc[0]['AddressFormatted']\n",
    "        if new_address in df['AddressFormatted'].values:\n",
    "            old_na_count = df[df['AddressFormatted'] == new_address].iloc[0]['NACount']\n",
    "            new_na_count = df_ap.iloc[0]['NACount']\n",
    "            if new_na_count < old_na_count:\n",
    "                df = df[~(df['AddressFormatted'] == new_address)]\n",
    "                df = df.append(df_ap[df_ap['AddressFormatted'] == new_address])\n",
    "        df_ap = df_ap[df_ap['AddressFormatted'] != new_address]\n",
    "    \n",
    "    \n",
    "    df.sort_values(by=['AddressFormatted'], inplace=True, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "# re-formatting for later analysis\n",
    "def format_df(df):\n",
    "    df['Cooling'] = df['Cooling'].apply(lambda x: True if x == '1' or x == 'True' or x is True else False)\n",
    "    \n",
    "    df['Price'] = df['Price'].apply(lambda x: numerical_object_to_float(x))\n",
    "    df['PropertyType'] = df['PropertyType'].apply(lambda x: numerical_object_to_float(x))\n",
    "    \n",
    "    df['Beds'] = df['Beds'].apply(lambda x: numerical_object_to_float(x))\n",
    "    df['Baths'] = df['Baths'].apply(lambda x: numerical_object_to_float(x))\n",
    "    \n",
    "    df['Sqft'] = df['Sqft'].apply(lambda x: numerical_object_to_float(x))\n",
    "    df['YearBuilt'] = df['YearBuilt'].apply(lambda x: numerical_object_to_float(x))\n",
    "    df['WalkScore'] = df['WalkScore'].apply(lambda x: numerical_object_to_float(x))\n",
    "    df['TransitScore'] = df['TransitScore'].apply(lambda x: numerical_object_to_float(x))\n",
    "    df['ParkingPrice'] = df['ParkingPrice'].apply(lambda x: numerical_object_to_float(x))\n",
    "    df['ParkingType'] = df['ParkingType'].apply(lambda x: numerical_object_to_float(x))\n",
    "    df['ParkingPrice'] = df['ParkingPrice'].apply(lambda x: numerical_object_to_float(x))\n",
    "    df['Cooling'] = df['Cooling'].apply(lambda x: bool_object_to_float(x))\n",
    "    df['Laundry'] = df['Laundry'].apply(lambda x: numerical_object_to_float(x))\n",
    "    df['Address'] = df['AddressFormatted']\n",
    "    \n",
    "    df = df.drop(columns=['AddressFormatted', 'NACount'])\n",
    "    \n",
    "#     df = df[(df['Sqft'] > 100.0) | (df['Sqft'] < 0.0)]\n",
    "    \n",
    "    \n",
    "    # assign median to missing values for certain columns\n",
    "#     df_median = median_without_nan(df)\n",
    "    return df\n",
    "\n",
    "def split_fill_df(df):\n",
    "    # dropna for bed and bath\n",
    "    df = df.dropna(subset=['Beds', 'Baths'], axis=0)\n",
    "    \n",
    "    df_y = df['Price']\n",
    "    df = df.drop(columns=['Price'])\n",
    "    df_train, df_test, y_train, y_test = train_test_split(df, df_y, test_size=0.1, random_state=15388)\n",
    "    \n",
    "    df_train = df_train.join(y_train)\n",
    "    df_test = df_test.join(y_test)\n",
    "    \n",
    "    df_train_median = median_without_nan(df_train)\n",
    "    df_test_median = median_without_nan(df_test)\n",
    "    \n",
    "    print(df_train_median)\n",
    "    \n",
    "    df_train['YearBuilt'] = df_train['YearBuilt'].apply(lambda x: df_train_median['YearBuilt'] if np.isnan(x) else x)\n",
    "    df_train['Sqft'] = df_train['Sqft'].apply(lambda x: df_train_median['Sqft'] if np.isnan(x) else x)\n",
    "    df_train['WalkScore'] = df_train['WalkScore'].apply(lambda x: df_train_median['WalkScore'] if np.isnan(x) else x)\n",
    "    df_train['TransitScore'] = df_train['TransitScore'].apply(lambda x: df_train_median['TransitScore'] if np.isnan(x) else x)\n",
    "    # cooling is already filled\n",
    "    df_train['Laundry'] = df_train['Laundry'].apply(lambda x: 0.0 if np.isnan(x) else x)\n",
    "    df_train['ParkingPrice'] = df_train['ParkingPrice'].apply(lambda x: 0.0 if np.isnan(x) else x)\n",
    "    df_train['ParkingType'] = df_train['ParkingType'].apply(lambda x: 0.0 if np.isnan(x) else x)\n",
    "    \n",
    "    df_test['YearBuilt'] = df_test['YearBuilt'].apply(lambda x: df_test_median['YearBuilt'] if np.isnan(x) else x)\n",
    "    df_test['Sqft'] = df_test['Sqft'].apply(lambda x: df_test_median['Sqft'] if np.isnan(x) else x)\n",
    "    df_test['WalkScore'] = df_test['WalkScore'].apply(lambda x: df_test_median['WalkScore'] if np.isnan(x) else x)\n",
    "    df_test['TransitScore'] = df_test['TransitScore'].apply(lambda x: df_test_median['TransitScore'] if np.isnan(x) else x)\n",
    "    # cooling is already filled\n",
    "    df_test['Laundry'] = df_test['Laundry'].apply(lambda x: 0.0 if np.isnan(x) else x)\n",
    "    df_test['ParkingPrice'] = df_test['ParkingPrice'].apply(lambda x: 0.0 if np.isnan(x) else x)\n",
    "    df_test['ParkingType'] = df_test['ParkingType'].apply(lambda x: 0.0 if np.isnan(x) else x)\n",
    "    \n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "df_zillow, df_ap, df_apf = load_file()\n",
    "df = merge_df(df_zillow, df_ap, df_apf)\n",
    "df = format_df(df)\n",
    "df_train, df_test = split_fill_df(df)\n",
    "\n",
    "df_train.to_csv('all_train.csv', encoding='utf-8', index=False)\n",
    "df_test.to_csv('all_test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-street",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
