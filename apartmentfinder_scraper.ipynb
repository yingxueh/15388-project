{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "apartmentfinder_scraper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1OwhfXCtpWL"
      },
      "source": [
        "!pip install slimit\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import re\n",
        "from slimit import ast\n",
        "from slimit.parser import Parser\n",
        "from slimit.visitors import nodevisitor\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPXfVtgztt-7"
      },
      "source": [
        "# input apartmentfinder url\n",
        "# returns number of pages\n",
        "def get_num_pages(url) :\n",
        "  header = {'Accept': 'text/html', \n",
        "            \"User-Agent\":'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'}\n",
        "  response = requests.get(url, headers = header)\n",
        "  root = BeautifulSoup(response.content, 'html.parser')\n",
        "  num_pages = int(root.find_all(\"div\", id = \"pagingTotal\")[0].find_all(\"span\")[0].text.split()[-1])\n",
        "  return num_pages\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn77m2zht6gV"
      },
      "source": [
        "# input number of pages and url to get apartment links from\n",
        "# returns list of links of apartments\n",
        "def get_links(num_pages, url) :\n",
        "  header = {'Accept': 'text/html', \n",
        "            \"User-Agent\":'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'}\n",
        "  links = []\n",
        "  for p in range(num_pages) :\n",
        "    print(p)\n",
        "    if p != 0 :\n",
        "      page = url + \"/Page\" + str(p+1)\n",
        "    else :\n",
        "      page = url\n",
        "    page_response = requests.get(page, headers = header, timeout = 20)\n",
        "    page_root = BeautifulSoup(page_response.content, 'html.parser')\n",
        "    apts = json.loads(page_root.find_all(\"script\", type = \"application/ld+json\", id = \"structuredSchemaBreadcrumb\")[0].text)[\"about\"]\n",
        "    for apt in apts :\n",
        "      links.append(apt[\"@id\"])\n",
        "    time.sleep(0.5)\n",
        "  return links"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClWnhvH-vWya"
      },
      "source": [
        "# input apartment page link\n",
        "# returns BeautifulSoup of apartment page\n",
        "def get_apt_root(link) :\n",
        "  header = {'Accept': 'text/html', \n",
        "            \"User-Agent\":'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'}\n",
        "  apt_response = requests.get(link, headers = header, timeout = 10)\n",
        "  apt_root = BeautifulSoup(apt_response.content, 'html.parser')\n",
        "  return apt_root\n",
        "\n",
        "# input BeautifulSoup of apartment page\n",
        "# returns javascript data as dictionary\n",
        "def get_js(apt_root) :\n",
        "  apt_info_js = apt_root.find_all(\"script\", type = \"text/javascript\")\n",
        "  if len(apt_info_js) == 0 :\n",
        "    return None\n",
        "  apt_info_js = apt_root.find_all(\"script\", type = \"text/javascript\")[-1]\n",
        "  parser = Parser()\n",
        "  tree = parser.parse(apt_info_js.text)\n",
        "  fields = {getattr(node.left, 'value', ''): getattr(node.right, 'value','') for node in nodevisitor.visit(tree) if isinstance(node, ast.Assign)}\n",
        "  return fields\n",
        "\n",
        "# input from get_js function\n",
        "# returns property type\n",
        "def get_proptype(fields) :\n",
        "  proptype = fields[\"propertyType\"][1:-1]\n",
        "  PropertyType = 0\n",
        "  if proptype == \"House\" :\n",
        "    PropertyType = 1\n",
        "  elif proptype == \"Condo\" :\n",
        "    PropertyType = 2\n",
        "  return PropertyType\n",
        "\n",
        "# input from get_js function and BeautifulSoup of apartment page\n",
        "# returns description\n",
        "def get_description(fields, apt_root) :\n",
        "  Description = fields[\"listingDescription\"][1:-1]\n",
        "  amenities_list = apt_root.find_all(\"section\", id = \"special-features\")\n",
        "  if len(amenities_list) != 0 :\n",
        "    amenities_list = apt_root.find_all(\"section\", id = \"special-features\")[0].find_all(\"li\")\n",
        "    Amenities = \"\"\n",
        "    if len(amenities_list) > 0 :\n",
        "      Amenities = amenities_list[0].text\n",
        "    if len(amenities_list) > 1 :\n",
        "      for a in amenities_list[1:] :\n",
        "        Amenities += \", \" + a.text\n",
        "    Description += \" \" + Amenities\n",
        "  return Description\n",
        "\n",
        "# input BeautifulSoup of apartment page\n",
        "# returns address\n",
        "def get_address(apt_root) :\n",
        "  Address = apt_root.find_all(\"span\", class_ = \"mailing-address\")[0].text\n",
        "  Address = re.sub(\" +\", \" \", Address)\n",
        "  return Address\n",
        "\n",
        "# input BeautifulSoup of apartment page\n",
        "# returns parking price and parking type as tuple\n",
        "def get_parking(apt_root) :\n",
        "  ParkingPrice = 0\n",
        "  ParkingType = 0\n",
        "  commfeats_list = apt_root.find_all(\"section\", id = \"community-features\")\n",
        "  if len(commfeats_list) > 0 :\n",
        "    commfeats_list = apt_root.find_all(\"section\", id = \"community-features\")[0].find_all(\"li\")\n",
        "    for c in commfeats_list :\n",
        "      if re.search(\"[Pp]arking\", c.text) != None :\n",
        "        ParkingType = 1\n",
        "  amenities_list = apt_root.find_all(\"section\", id = \"special-features\")\n",
        "  if len(amenities_list) != 0 :\n",
        "    amenities_list = apt_root.find_all(\"section\", id = \"special-features\")[0].find_all(\"li\")\n",
        "    if len(amenities_list) > 1 :\n",
        "      for a in amenities_list[1:] :\n",
        "        if re.search(\"[Pp]arking\", a.text) != None :\n",
        "          ParkingType = 1\n",
        "  expenses_list = apt_root.find_all(\"li\", class_ = \"expense-line\")\n",
        "  for i in range(len(expenses_list)) :\n",
        "    if re.search(\"[Pp]arking\", expenses_list[i].text) != None :\n",
        "      ParkingType = 1\n",
        "      ParkingPrice = int(re.findall(\"\\$[0-9]+\", expenses_list[i-1].text)[0][1:])\n",
        "  return ParkingPrice, ParkingType\n",
        "\n",
        "# input BeautifulSoup of apartment page\n",
        "# returns laundry type\n",
        "def get_laundry(apt_root) :\n",
        "  Laundry = 0\n",
        "  commfeats_list = apt_root.find_all(\"section\", id = \"community-features\")\n",
        "  if len(commfeats_list) > 0 :\n",
        "    commfeats_list = apt_root.find_all(\"section\", id = \"community-features\")[0].find_all(\"li\")\n",
        "    for c in commfeats_list :\n",
        "      if c.text == \"Laundry Facilities\" :\n",
        "        Laundry = 1\n",
        "  amenities_list = apt_root.find_all(\"section\", id = \"special-features\")\n",
        "  if len(amenities_list) != 0 :\n",
        "    amenities_list = apt_root.find_all(\"section\", id = \"special-features\")[0].find_all(\"li\")\n",
        "    if len(amenities_list) > 1 :\n",
        "      for a in amenities_list[1:] :\n",
        "        if re.search(\"[Ww]asher\", a.text) != None or re.search(\"[Dd]ryer\", a.text) != None or re.search(\"[Ll]aundry\", a.text) != None :\n",
        "          Laundry = 3\n",
        "  return Laundry\n",
        "\n",
        "# input BeautifulSoup of apartment page\n",
        "# returns if apartment has cooling\n",
        "def get_cooling(apt_root) :\n",
        "  Cooling = False\n",
        "  fpfeatures_list = apt_root.find_all(\"section\", id = \"floorplan-amenities\")\n",
        "  if len(fpfeatures_list) > 0 :\n",
        "    fpfeatures_list = apt_root.find_all(\"section\", id = \"floorplan-amenities\")[0].find_all(\"li\")\n",
        "    for feat in fpfeatures_list :\n",
        "      if feat.text == \"Air Conditioning\" :\n",
        "        Cooling = True\n",
        "  return Cooling\n",
        "\n",
        "# input BeautifulSoup of apartment page\n",
        "# returns year that apartment building was built\n",
        "def get_yearbuilt(apt_root) :\n",
        "  built_text = apt_root.find(\"div\", class_ = \"row description-container section-content\").text\n",
        "  built_start = re.search(\"built in \", built_text)\n",
        "  YearBuilt = None\n",
        "  if built_start != None :\n",
        "    built_start = re.search(\"built in \", built_text).start()\n",
        "    if built_start != None :\n",
        "      y = built_text[built_start + len(\"built in \"):built_start + len(\"built in \") + 4]\n",
        "      if y.isdigit() :\n",
        "        YearBuilt = int(built_text[built_start + len(\"built in \"):built_start + len(\"built in \") + 4])\n",
        "  return YearBuilt\n",
        "\n",
        "# input address\n",
        "# returns BeautifulSoup of walkscore page\n",
        "def get_ws_root(Address) :\n",
        "  address_string = re.sub(\",\", \"\", Address.lower())\n",
        "  address_string = re.sub(\" +\", \"-\", address_string)\n",
        "  walkscore_link = \"https://www.walkscore.com/score/\" + address_string\n",
        "  ws_response = requests.get(walkscore_link, headers = header)\n",
        "  ws_root = BeautifulSoup(ws_response.content, \"html.parser\")\n",
        "  return ws_root\n",
        "\n",
        "# input BeautifulSoup of walkscore page\n",
        "# returns walkscore\n",
        "def get_walkscore(ws_root) :\n",
        "  if len(ws_root) == 0 :\n",
        "    return None\n",
        "  WalkScore = None\n",
        "  ws_text = ws_root.find_all(\"span\", id = \"score-description-sentence\")[0].text\n",
        "  ws_start = re.search(\"Walk Score of \", ws_text)\n",
        "  if ws_start != None :\n",
        "    ws_start = re.search(\"Walk Score of \", ws_text).start()\n",
        "    ws_slice = ws_text[ws_start + len(\"Walk Score of \"):]\n",
        "    ws_end = re.search(\" \", ws_slice).start()\n",
        "    WalkScore = int(ws_slice[:ws_end])\n",
        "  return WalkScore\n",
        "\n",
        "# input BeautifulSoup of walkscore page\n",
        "# returns transitscore\n",
        "def get_transitscore(ws_root) :\n",
        "  if len(ws_root) == 0 :\n",
        "    return None\n",
        "  TransitScore = None\n",
        "  ws_root_str = str(ws_root)\n",
        "  ts_start = re.search(\"//pp\\.walk\\.sc/badge/transit/score/\", ws_root_str)\n",
        "  if ts_start != None :\n",
        "    ts_start = ts_start.start()\n",
        "    ts_slice = ws_root_str[ts_start:]\n",
        "    start = re.search(\"[0-9]\", ts_slice).start()\n",
        "    end = re.search(r'\\.png', ts_slice).start()\n",
        "    TransitScore = int(ts_slice[start:end])\n",
        "  return TransitScore\n",
        "\n",
        "# input BeautifulSoup of apartment page\n",
        "# returns 2d list of data\n",
        "def get_info(apt_root, PropertyType, Description, Address, ParkingPrice, ParkingType, Laundry, Cooling, YearBuilt, WalkScore, TransitScore) :\n",
        "  data = []\n",
        "  apt_info_js = apt_root.find_all(\"script\", type = \"text/javascript\")\n",
        "  if len(apt_info_js) == 0 :\n",
        "    return None\n",
        "  apt_info_js = apt_root.find_all(\"script\", type = \"text/javascript\")[-1]\n",
        "  apt_info = apt_info_js.text\n",
        "  rentals_start = re.search(\"rentals: \", apt_info).start()\n",
        "  rentals_end = re.search(\"fees: \", apt_info).start()\n",
        "  rentals_info = json.loads(apt_info[rentals_start + len(\"rentals: \"):rentals_end].strip()[:-1])\n",
        "  rental_types = dict()\n",
        "  rental_type_in = dict()\n",
        "  for rental in rentals_info :\n",
        "    if rental[\"DateAvailableDisplay\"] != \"Not Available\" :\n",
        "      price = rental[\"MinRent\"].strip()\n",
        "      if re.search(\"[0-9]\", price) != None :\n",
        "        beds = int(rental[\"Beds\"])\n",
        "        baths = float(rental[\"Baths\"])\n",
        "        price = int(rental[\"MinRent\"])\n",
        "        if (beds, baths) not in rental_types.keys() :\n",
        "          rental_types[(beds,baths)] = price\n",
        "          rental_type_in[(beds,baths)] = False\n",
        "        else :\n",
        "          if rental_types[(beds,baths)] > price :\n",
        "            rental_types[(beds,baths)] = price\n",
        "  for rental in rentals_info :\n",
        "    if rental[\"DateAvailableDisplay\"] != \"Not Available\" :\n",
        "      Baths = float(rental[\"Baths\"])\n",
        "      Beds = int(rental[\"Beds\"])\n",
        "      Price = rental[\"MinRent\"].strip()\n",
        "      if re.search(\"[0-9]\", Price) != None :\n",
        "        Price = int(rental[\"MinRent\"])\n",
        "        if rental_types[(Beds,Baths)] == Price and rental_type_in[(Beds,Baths)] == False:\n",
        "          sqft_str = rental[\"SquareFootDisplay\"]\n",
        "          if sqft_str == None :\n",
        "            continue\n",
        "          sqft_num = sqft_str[:re.search(\" Sq Ft\", sqft_str).start()]\n",
        "          Sqft = int(re.sub(\",\", \"\", sqft_num))\n",
        "          row = [Price, Address, PropertyType, Beds, Baths, Sqft, YearBuilt, WalkScore, TransitScore, ParkingPrice, ParkingType, Cooling, \n",
        "                  Laundry, Description]\n",
        "          if len(row) == 14 :\n",
        "            data.append(row)\n",
        "          rental_type_in[(Beds,Baths)] = True\n",
        "  return data\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh4buE357R3h"
      },
      "source": [
        "# input links\n",
        "# returns 2d list of data\n",
        "def get_data(links) :\n",
        "  data = []\n",
        "  for link in links :\n",
        "    apt_root = get_apt_root(link)\n",
        "    fields = get_js(apt_root)\n",
        "    if fields != None :\n",
        "      PropertyType = get_proptype(fields)\n",
        "      Description = get_description(fields, apt_root)\n",
        "      Address = get_address(apt_root)\n",
        "      ParkingPrice, ParkingType = get_parking(apt_root)\n",
        "      Laundry = get_laundry(apt_root)\n",
        "      Cooling = get_cooling(apt_root)\n",
        "      YearBuilt = get_yearbuilt(apt_root)\n",
        "      ws_root = get_ws_root(Address)\n",
        "      WalkScore = get_walkscore(ws_root)\n",
        "      TransitScore = get_transitscore(ws_root)\n",
        "      apt_data = get_info(apt_root, PropertyType, Description, Address, ParkingPrice, ParkingType, Laundry, Cooling, YearBuilt, WalkScore, TransitScore)\n",
        "      if apt_data != None :\n",
        "        for row in apt_data :\n",
        "          data.append(row)\n",
        "    time.sleep(0.5)\n",
        "  return data\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGLzbLpj99Er"
      },
      "source": [
        "main_url = \"https://www.apartmentfinder.com/Pennsylvania/Pittsburgh-Apartments\"\n",
        "num_pages = get_num_pages(main_url)\n",
        "links = get_links(num_pages, main_url)\n",
        "data = get_data(links)\n",
        "df = pd.DataFrame(data, columns = [\"Price\", \"Address\", \"PropertyType\", \"Beds\", \"Baths\", \"Sqft\", \"YearBuilt\", \"WalkScore\", \n",
        "                                   \"TransitScore\", \"ParkingPrice\", \"ParkingType\", \"Cooling\", \"Laundry\", \"Description\"])\n",
        "\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0PmqeIz4sLO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "with open('/gdrive/My Drive/apartmentfinder.csv', 'a') as f:\n",
        "  df.to_csv(f, header = False, index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
